<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu">
  <meta name="description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <meta name="keywords" content="Computer vision, Machine learning, Data science, Deep learning, Artificial intelligence">
  <meta name="author" content="Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="The University of Sydney">
  <meta property="og:title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <meta property="og:description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <meta property="og:url" content="https://yuguanghu.com/SHRIMP-Page/">
  <meta property="og:image" content="https://yuguanghu.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Research Preview">
  <meta property="article:published_time" content="2025-12-19T00:00:00.000Z">
  <meta property="article:author" content="Yuguang Hu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Computer vision">
  <meta property="article:tag" content="Machine learning">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE"> -->
  <!-- <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE"> -->
  <meta name="twitter:title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <meta name="twitter:description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <meta name="twitter:image" content="https://yuguanghu.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <meta name="citation_author" content="Hu, Yuguang">
  <meta name="citation_author" content="Liu, Daochang">
  <meta name="citation_author" content="Protat, Alain">
  <meta name="citation_author" content="Louf, Valentin">
  <meta name="citation_author" content="Brook, Jordan">
  <meta name="citation_author" content="Xu, Chang">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_journal_title" content="Artificial Intelligence for the Earth Systems">
  <meta name="citation_pdf_url" content="https://yuguanghu.com/static/pdfs/aies-AIES-D-25-0016.1.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models",
    "description": "‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.",
    "author": [
      {
        "@type": "Person",
        "name": "Yuguang Hu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Sydney"
        }
      },
      {
        "@type": "Person",
        "name": "Daochang Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Western Australia"
        }
      },
      {
        "@type": "Person",
        "name": "Alain Protat",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Valentin Louf",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Jordan Brook",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Chang Xu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Sydney"
        }
      }
    ],
    "datePublished": "2025-12-19",
    "publisher": {
      "@type": "Organization",
      "name": "Artificial Intelligence for the Earth Systems"
    },
    "url": "https://yuguanghu.com/SHRIMP-Page/",
    "image": "https://yuguanghu.com/static/images/social_preview.png",
    "keywords": ["Computer vision", "Machine learning", "Data science", "Deep learning", "Artificial intelligence"],
    "abstract": "The limited coverage of radar sites has given rise to a demand for transforming the extensive coverage of weather satellite observations into high-resolution and accurate synthetic radar reflectivity imagery. In this study, we introduce a new method that utilizes generative diffusion models to address this challenge. Starting from pure noise, our diffusion model takes infrared images from the Himawari geostationary weather satellite and lightning observations from a ground-based network as inputs to control the generation process. The model‚Äôs iterative diffusion and denoising process helps capture the intrinsic uncertainty of satellite-to-radar transformation by generating probabilistic results, whereas nongenerative methods can only produce deterministic outputs. Our new technique improves the granularity and spatial accuracy of synthetic radar reflectivity imagery compared to previously published nongenerative U-Net models. In our experiments, the new technique enhances the emulation of severe weather by capturing finer visual structures in areas with strong radar echoes. Results show that images generated by our model outperform traditional U-Net models on key metrics such as the fractions skill score (FSS) across multiple thresholds, with the average FSS increasing from 0.40 to 0.50, and also produce a much improved statistical distribution of reflectivity, especially at the low and high ends of the distribution.",
    "citation": "@article{EnhancingProductionofSyntheticRadarImagesfromGeostationarySatelliteObservationsthroughGenerativeDiffusionModels, author = \"Yuguang Hu and Daochang Liu and Alain Protat and Valentin Louf and Jordan Brook and Chang Xu\", title = \"Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models\", journal = \"Artificial Intelligence for the Earth Systems\", year = \"2026\", publisher = \"American Meteorological Society\", address = \"Boston MA, USA\", volume = \"5\", number = \"1\", doi = \"10.1175/AIES-D-25-0016.1\", pages = \"e250016\", url = \"https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml\"}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://yuguanghu.com/SHRIMP-Page/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Computer vision"
      },
      {
        "@type": "Thing", 
        "name": "Machine learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "The University of Sydney",
    "url": "https://www.sydney.edu.au/",
    "logo": "https://yuguanghu.com/static/images/favicon.ico",
    "sameAs": [
      "https://github.com/Ahyg"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <!--
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 1</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>
  -->

  <main id="main-content">
  <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <!-- Paper title -->
          <h1 class="title is-1 publication-title">
            Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models
          </h1>

          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuguanghu.com/" target="_blank" rel="noopener">Yuguang Hu</a>,
            </span>
            <span class="author-block">
              <a href="https://daochang.site/" target="_blank" rel="noopener">Daochang Liu</a>,
            </span>
            <span class="author-block">Alain Protat,</span>
            <span class="author-block">Valentin Louf,</span>
            <span class="author-block">Jordan Brook,</span>
            <span class="author-block">
              <a href="http://changxu.xyz/" target="_blank" rel="noopener">Chang Xu</a>
            </span>
          </div>

          <!-- Affiliations / Venue -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              The University of Sydney &amp; The Bureau of Meteorology<br>
              <em>Artificial Intelligence for the Earth Systems (AIES), 2026</em>
            </span>
          </div>

          <!-- Links -->
          <div class="publication-links">

            <!-- Paper (AMS PDF tab) -->
            <span class="link-block">
              <a href="https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml?tab_body=pdf"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>

            <!-- Code -->
            <span class="link-block">
              <a href="https://github.com/Ahyg/SHRIMP"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>

            <!-- DOI -->
            <span class="link-block">
              <a href="https://doi.org/10.1175/AIES-D-25-0016.1"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-link"></i>
                </span>
                <span>DOI</span>
              </a>
            </span>

          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- Motivation / Overview -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Motivation</h2>

    <div class="content has-text-justified">
      <p>
        Weather radar observations are critical for severe weather monitoring and nowcasting, yet their spatial coverage is limited, particularly across remote regions of Australia. This motivates the development of machine learning-based methods that can transform wide-coverage satellite observations into radar-like reflectivity imagery.
      </p>
    </div>

    <figure>
      <img src="static/images/fig1_overview.jpg"
           alt="Weather radars, radar image, satellite image, lightning observation"
           loading="lazy">
      <figcaption class="has-text-centered">
        <strong>Overview.</strong> Weather radars; radar image; satellite image; lightning observation.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The limited coverage of radar sites has given rise to a demand for transforming the extensive coverage of weather satellite observations into high-resolution and accurate synthetic radar reflectivity imagery. In this study, we introduce a new method that utilizes generative diffusion models to address this challenge. Starting from pure noise, our diffusion model takes infrared images from the Himawari geostationary weather satellite and lightning observations from a ground-based network as inputs to control the generation process. The model‚Äôs iterative diffusion and denoising process helps capture the intrinsic uncertainty of satellite-to-radar transformation by generating probabilistic results, whereas nongenerative methods can only produce deterministic outputs. Our new technique improves the granularity and spatial accuracy of synthetic radar reflectivity imagery compared to previously published nongenerative U-Net models. In our experiments, the new technique enhances the emulation of severe weather by capturing finer visual structures in areas with strong radar echoes. Results show that images generated by our model outperform traditional U-Net models on key metrics such as the fractions skill score (FSS) across multiple thresholds, with the average FSS increasing from 0.40 to 0.50, and also produce a much improved statistical distribution of reflectivity, especially at the low and high ends of the distribution.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Generation Results & Uncertainty -->
<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title is-3 has-text-centered">
      Uncertainty Analysis &amp; Case Studies
    </h2>

    <div class="content has-text-justified">
      <p>
        Unlike deterministic approaches (e.g., U-Net), diffusion models naturally produce ensembles of plausible radar images.
        This enables explicit analysis of generation uncertainty and spatial variability under identical satellite and lightning conditions.
      </p>
    </div>

    <!-- Uncertainty analysis (image) -->
    <figure class="image figure-max">
      <img src="static/images/UncertaintyAnalysisall.jpg"
           alt="Uncertainty analysis: multiple diffusion samples and variance map"
           loading="lazy">
    </figure>
    <p class="has-text-centered mt-3">
      <strong>Uncertainty analysis.</strong> Comparison of repeated diffusion model sampling outputs and variance maps. (top to bottom) Satellite and lightning image (regions of lightning activity are marked with red dashed lines), ground truth radar image, average diffusion output, best diffusion output, worst diffusion output, median diffusion output, and variance map. The evaluation of the diffusion model‚Äôs sampling results is based on the average FSS scores, which determine the quality of the outputs.
    </p>

    <hr class="my-5">

    <!-- Example generations (image) -->
    <figure class="image figure-max">
      <img src="static/images/2examples.jpg"
           alt="Case studies: baseline U-Net vs diffusion model outputs"
           loading="lazy">
    </figure>
    <p class="has-text-centered mt-3">
      <strong>Example generations.</strong> Comparison of the diffusion model and the baseline U-Net outputs. Case 1 highlights extensive cloud coverage, while case 2 shows limited cloud coverage. (left to right) Satellite and lightning visualization (lightning regions marked by red dashed lines), ground truth radar images, baseline U-Net outputs, and diffusion model median outputs. Metrics shown include MSE, R¬≤, FSS, CSI35, POD35, and FAR35.
    </p>

  </div>
</section>

<!-- Methodology -->
<section class="section hero is-light">
  <div class="container is-max-desktop">

    <h2 class="title is-3 has-text-centered">
      Methodology: Conditional Diffusion Framework
    </h2>

    <div class="content has-text-justified">
      <p>
        We adopt a conditional diffusion framework, where satellite infrared channels and lightning observations
        serve as conditioning inputs. A modified U-Net backbone with multi-scale feature extraction and time
        embeddings is used to predict clean radar reflectivity fields from noisy inputs.
      </p>
    </div>

    <!-- Diffusion process -->
    <figure class="image figure-max">
      <img src="static/images/DiffusionProcess.jpg"
           alt="Forward diffusion and reverse denoising process"
           loading="lazy">
    </figure>
    <p class="has-text-centered mt-3">
      <strong>Diffusion process.</strong>
      Illustration of the forward noising process and the reverse denoising generation procedure.
    </p>

    <hr class="my-5">

    <!-- Architecture: training & sampling -->
    <div class="columns is-variable is-6">
      <div class="column is-6">
        <figure class="image figure-small">
          <img src="static/images/Architecture2.jpg"
               alt="Training loop of the conditional diffusion model"
               loading="lazy">
        </figure>
        <p class="has-text-centered mt-3">
          <strong>Training loop.</strong>
          Noise injection and conditional denoising during model optimization.
        </p>
      </div>

      <div class="column is-6">
        <figure class="image figure-small">
          <img src="static/images/Architecture3.jpg"
               alt="Sampling loop of the conditional diffusion model"
               loading="lazy">
        </figure>
        <p class="has-text-centered mt-3">
          <strong>Sampling loop.</strong>
          Iterative generation from pure noise conditioned on satellite and lightning observations.
        </p>
      </div>
    </div>

  </div>
</section>


<!-- Quantitative Evaluation -->
<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title is-3 has-text-centered">Quantitative Evaluation</h2>

    <div class="content has-text-justified">
      <p>
        We evaluate the generated radar reflectivity images using meteorologically meaningful metrics,
        including the Fractions Skill Score (FSS) across multiple thresholds and spatial scales, as well as
        distributional comparisons of reflectivity values.
      </p>
    </div>

    <!-- FSS -->
    <figure class="image figure-medium">
      <img src="static/images/overall_fss.jpg"
           alt="Fractions Skill Score (FSS) evaluation across thresholds and scales"
           loading="lazy">
    </figure>
    <p class="has-text-centered mt-3">
      <strong>FSS evaluation.</strong>
      Performance across thresholds and spatial scales.
    </p>

    <br><br>

    <!-- KDE / PDF -->
    <figure class="image figure-medium">
      <img src="static/images/kde_reflectivity_PDF.jpg"
           alt="Reflectivity distribution comparison using KDE and PDF"
           loading="lazy">
    </figure>
    <p class="has-text-centered mt-3">
      <strong>Reflectivity distribution.</strong>
      KDE/PDF comparison between generated and real radar reflectivity.
    </p>

  </div>
</section>


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Poster for NVIDIA GTC 2026.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!-- BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>

    <pre id="bibtex-code"><code>@article{Hu2026SyntheticRadarDiffusion,
  title     = {Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models},
  author    = {Hu, Yuguang and Liu, Daochang and Protat, Alain and Louf, Valentin and Brook, Jordan and Xu, Chang},
  journal   = {Artificial Intelligence for the Earth Systems},
  year      = {2026},
  volume    = {5},
  number    = {1},
  pages     = {e250016},
  publisher = {American Meteorological Society},
  address   = {Boston, MA, USA},
  doi       = {10.1175/AIES-D-25-0016.1},
  url       = {https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml}
}</code></pre>

  </div>
</section>
<!-- End BibTeX citation -->

</main>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
