<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="Computer vision, Machine learning, Data science, Deep learning, Artificial intelligence">
  <!-- TODO: List all authors -->
  <meta name="author" content="Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="The University of Sydney">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://yuguanghu.com/SHRIMP-Page/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://yuguanghu.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Research Preview">
  <meta property="article:published_time" content="2025-12-19T00:00:00.000Z">
  <meta property="article:author" content="Yuguang Hu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Computer vision">
  <meta property="article:tag" content="Machine learning">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <!-- <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE"> -->
  <!-- TODO: Replace with first author's Twitter handle -->
  <!-- <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE"> -->
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://yuguanghu.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models">
  <meta name="citation_author" content="Hu, Yuguang">
  <meta name="citation_author" content="Liu, Daochang">
  <meta name="citation_author" content="Protat, Alain">
  <meta name="citation_author" content="Louf, Valentin">
  <meta name="citation_author" content="Brook, Jordan">
  <meta name="citation_author" content="Xu, Chang">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_journal_title" content="Artificial Intelligence for the Earth Systems">
  <meta name="citation_pdf_url" content="https://yuguanghu.com/static/pdfs/aies-AIES-D-25-0016.1.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models - Yuguang Hu, Daochang Liu, Alain Protat, Valentin Louf, Jordan Brook, Chang Xu | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models",
    "description": "‚òÅÔ∏èüå©Ô∏èüå¶Ô∏èüåßÔ∏è‚õàÔ∏è Advancing the application of generative AI in meteorology! Radar observations play a crucial role in modern weather monitoring and nowcasting, but their spatial coverage is limited. This research leverages diffusion models to generate radar reflectivity images from geostationary satellite observations. Our findings show that diffusion models can not only reproduce radar-like spatial structures, but also deliver strong performance across meteorologically relevant metrics. This opens up promising directions for integrating generative AI into future weather nowcasting and data assimilation systems.",
    "author": [
      {
        "@type": "Person",
        "name": "Yuguang Hu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Sydney"
        }
      },
      {
        "@type": "Person",
        "name": "Daochang Liu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Western Australia"
        }
      },
      {
        "@type": "Person",
        "name": "Alain Protat",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Valentin Louf",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Jordan Brook",
        "affiliation": {
          "@type": "Organization",
          "name": "Bureau of Meteorology"
        }
      },
      {
        "@type": "Person",
        "name": "Chang Xu",
        "affiliation": {
          "@type": "Organization",
          "name": "The University of Sydney"
        }
      }
    ],
    "datePublished": "2025-12-19",
    "publisher": {
      "@type": "Organization",
      "name": "Artificial Intelligence for the Earth Systems"
    },
    "url": "https://yuguanghu.com/SHRIMP-Page/",
    "image": "https://yuguanghu.com/static/images/social_preview.png",
    "keywords": ["Computer vision", "Machine learning", "Data science", "Deep learning", "Artificial intelligence"],
    "abstract": "The limited coverage of radar sites has given rise to a demand for transforming the extensive coverage of weather satellite observations into high-resolution and accurate synthetic radar reflectivity imagery. In this study, we introduce a new method that utilizes generative diffusion models to address this challenge. Starting from pure noise, our diffusion model takes infrared images from the Himawari geostationary weather satellite and lightning observations from a ground-based network as inputs to control the generation process. The model‚Äôs iterative diffusion and denoising process helps capture the intrinsic uncertainty of satellite-to-radar transformation by generating probabilistic results, whereas nongenerative methods can only produce deterministic outputs. Our new technique improves the granularity and spatial accuracy of synthetic radar reflectivity imagery compared to previously published nongenerative U-Net models. In our experiments, the new technique enhances the emulation of severe weather by capturing finer visual structures in areas with strong radar echoes. Results show that images generated by our model outperform traditional U-Net models on key metrics such as the fractions skill score (FSS) across multiple thresholds, with the average FSS increasing from 0.40 to 0.50, and also produce a much improved statistical distribution of reflectivity, especially at the low and high ends of the distribution.",
    "citation": "@article{EnhancingProductionofSyntheticRadarImagesfromGeostationarySatelliteObservationsthroughGenerativeDiffusionModels, author = \"Yuguang Hu and Daochang Liu and Alain Protat and Valentin Louf and Jordan Brook and Chang Xu\", title = \"Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models\", journal = \"Artificial Intelligence for the Earth Systems\", year = \"2026\", publisher = \"American Meteorological Society\", address = \"Boston MA, USA\", volume = \"5\", number = \"1\", doi = \"10.1175/AIES-D-25-0016.1\", pages = \"e250016\", url = \"https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml\"}"
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://yuguanghu.com/SHRIMP-Page/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Computer vision"
      },
      {
        "@type": "Thing", 
        "name": "Machine learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "The University of Sydney",
    "url": "https://www.sydney.edu.au/",
    "logo": "https://yuguanghu/static/images/favicon.ico",
    "sameAs": [
      <!-- "https://twitter.com/YOUR_TWITTER_HANDLE", -->
      "https://github.com/Ahyg"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <!--
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 1</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>
  -->

  <main id="main-content">
  <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <!-- Paper title -->
          <h1 class="title is-1 publication-title">
            Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models
          </h1>

          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuguanghu.com/" target="_blank" rel="noopener">Yuguang Hu</a>,
            </span>
            <span class="author-block">
              <a href="https://daochang.site/" target="_blank" rel="noopener">Daochang Liu</a>,
            </span>
            <span class="author-block">Alain Protat,</span>
            <span class="author-block">Valentin Louf,</span>
            <span class="author-block">Jordan Brook,</span>
            <span class="author-block">
              <a href="http://changxu.xyz/" target="_blank" rel="noopener">Chang Xu</a>
            </span>
          </div>

          <!-- Affiliations / Venue -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              The University of Sydney &amp; The Bureau of Meteorology<br>
              <em>Artificial Intelligence for the Earth Systems (AIES), 2026</em>
            </span>
          </div>

          <!-- Links -->
          <div class="publication-links">

            <!-- Paper (AMS PDF tab) -->
            <span class="link-block">
              <a href="https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml?tab_body=pdf"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>

            <!-- Code -->
            <span class="link-block">
              <a href="https://github.com/Ahyg/SHRIMP"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>

            <!-- DOI -->
            <span class="link-block">
              <a href="https://doi.org/10.1175/AIES-D-25-0016.1"
                 target="_blank" rel="noopener"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-link"></i>
                </span>
                <span>DOI</span>
              </a>
            </span>

          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- Motivation / Overview -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Motivation &amp; Overview</h2>

    <div class="content has-text-justified">
      <p>
        Weather radar observations are critical for severe weather monitoring and nowcasting, yet their spatial coverage is limited, particularly across remote regions of Australia. This motivates the development of learning-based methods that can transform wide-coverage satellite observations into radar-like reflectivity imagery.
      </p>
    </div>

    <figure>
      <img src="static/images/fig1_overview.jpg"
           alt="Weather radars, radar image, satellite image, lightning observation"
           loading="lazy">
      <figcaption class="has-text-centered">
        <strong>Fig. 1.</strong> Weather radars; radar image; satellite image; lightning observation.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            The limited coverage of radar sites has given rise to a demand for transforming the extensive coverage of weather satellite observations into high-resolution and accurate synthetic radar reflectivity imagery. In this study, we introduce a new method that utilizes generative diffusion models to address this challenge. Starting from pure noise, our diffusion model takes infrared images from the Himawari geostationary weather satellite and lightning observations from a ground-based network as inputs to control the generation process. The model‚Äôs iterative diffusion and denoising process helps capture the intrinsic uncertainty of satellite-to-radar transformation by generating probabilistic results, whereas nongenerative methods can only produce deterministic outputs. Our new technique improves the granularity and spatial accuracy of synthetic radar reflectivity imagery compared to previously published nongenerative U-Net models. In our experiments, the new technique enhances the emulation of severe weather by capturing finer visual structures in areas with strong radar echoes. Results show that images generated by our model outperform traditional U-Net models on key metrics such as the fractions skill score (FSS) across multiple thresholds, with the average FSS increasing from 0.40 to 0.50, and also produce a much improved statistical distribution of reflectivity, especially at the low and high ends of the distribution.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Generation Results & Uncertainty -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Generation Results &amp; Uncertainty Analysis</h2>

    <div class="content has-text-justified">
      <p>
        Unlike deterministic regression-based approaches, diffusion models naturally produce ensembles
        of plausible radar realizations. This enables explicit analysis of generation uncertainty and
        spatial variability under identical satellite and lightning conditions.
      </p>
    </div>

    <div class="columns is-multiline">
      <div class="column is-6">
        <iframe src="static/pdfs/UncertaintyAnalysisall.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Uncertainty analysis.</strong> Ensemble statistics and variance maps.
        </p>
      </div>

      <div class="column is-6">
        <iframe src="static/pdfs/2examples.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Example generations.</strong> Multiple diffusion samples under identical conditions.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Methodology -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Methodology: Conditional Diffusion Framework</h2>

    <div class="content has-text-justified">
      <p>
        We adopt a conditional diffusion framework based on DDIM, where satellite infrared channels
        and lightning observations serve as conditioning inputs. A modified U-Net backbone with
        multi-scale features and time embedding is used to predict clean radar reflectivity from
        noisy inputs.
      </p>
    </div>

    <div class="columns">
      <div class="column is-12">
        <iframe src="static/pdfs/DiffusionProcess.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Diffusion process.</strong> Forward noising and reverse denoising.
        </p>
      </div>
    </div>

    <div class="columns">
      <div class="column is-6">
        <iframe src="static/pdfs/Architecture2.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Training loop.</strong> Noise injection and conditional denoising.
        </p>
      </div>

      <div class="column is-6">
        <iframe src="static/pdfs/Architecture3.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Sampling loop.</strong> Iterative generation from pure noise.
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Quantitative Evaluation -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Quantitative Evaluation</h2>

    <div class="content has-text-justified">
      <p>
        We evaluate the generated radar reflectivity fields using meteorologically meaningful
        metrics, including the Fractions Skill Score (FSS) across multiple thresholds and spatial
        scales, as well as distributional consistency of reflectivity values.
      </p>
    </div>

    <div class="columns">
      <div class="column is-6">
        <iframe src="static/pdfs/overall_fss.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>FSS evaluation.</strong> Performance across thresholds and scales.
        </p>
      </div>

      <div class="column is-6">
        <iframe src="static/pdfs/kde_reflectivity_PDF.pdf"
                width="100%" height="420"></iframe>
        <p class="has-text-centered">
          <strong>Reflectivity distribution.</strong> KDE and PDF comparison with real radar.
        </p>
      </div>
    </div>
  </div>
</section>


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdfs/aies-AIES-D-25-0016.1.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!-- BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>

    <pre id="bibtex-code"><code>@article{Hu2026SyntheticRadarDiffusion,
  title     = {Enhancing Production of Synthetic Radar Images from Geostationary Satellite Observations through Generative Diffusion Models},
  author    = {Hu, Yuguang and Liu, Daochang and Protat, Alain and Louf, Valentin and Brook, Jordan and Xu, Chang},
  journal   = {Artificial Intelligence for the Earth Systems},
  year      = {2026},
  volume    = {5},
  number    = {1},
  pages     = {e250016},
  publisher = {American Meteorological Society},
  address   = {Boston, MA, USA},
  doi       = {10.1175/AIES-D-25-0016.1},
  url       = {https://journals.ametsoc.org/view/journals/aies/5/1/AIES-D-25-0016.1.xml}
}</code></pre>

  </div>
</section>
<!-- End BibTeX citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
